# CLCC
CLCC is an LLM-based DBMS fuzzing tool. It can generate initial seeds and continuously mutate them during fuzzing. By leveraging the LLM’s understanding of SQL semantics and structure, CLCC can test multiple DBMSs, explore more execution paths, and attempt to trigger crashes and other bugs.

## For CLCC (Base on Squirrel)
CLCC can be rapidly integrated with any DBMS fuzzing tool (and even with non-DBMS fuzzers—by adjusting the prompts in CLCC, it can be quickly adapted to different targets). Below, we demonstrate how to run CLCC extended on top of Squirrel.

### Quick Start
Here is a minimal runnable example (testing SQLite). For the meanings of specific parameters and instructions for testing additional DBMSs, please refer to the documentation below.

##### Prerequisites
- Ubuntu 22.04 / Windows 11
- Git
- Docker
- LLM API key & LLM base URL

#### Quick Start Command
```shell
git clone https://github.com/zrclzrcl/CLCC.git
cd ./CLCC
rm -rf ./docker/set_seed
cp -a ./docker/sqlite/seeds/BGSeed ./docker/set_seed
docker build -f ./docker/sqlite/dockers/clcc_dockerfile -t sqlite_clcc .

# You will need two terminal windows for the following steps.
# In terminal-1 run:
docker run -it --name clcc4sqlite sqlite_clcc /bin/bash

cd /home/clcc && python3 count_feedbackpoint.py -t 0.1 -db sqlite -v "3.30.0" -o 1 -k "Your LLM API KEY Here!" -conf "" -norm 12 -pn 2 -win 500 -ms 50000 -mo gemini-2.0-flash -bu "Your LLM Base URL Here!"

# In terminal-2 run:
docker exec -it clcc4sqlite /bin/bash
# Next command will start fuzz!
python3 clcc_run.py sqlite /home/Squirrel/data/fuzz_root/set_seed/
```

#### What to Expect

After running the fuzzing process, you can expect the following outputs:

**Generated LLM Test Cases**: `/home/LLM_testcase/`
- Files named `LLM_G_{number}.txt` containing SQL test cases

**AFL++ Output File**: `/tmp/fuzz/default/` or `/tmp/clcc`
- Test cases that successfully triggered crashes in the DBMS
- Test cases that caused the database to hang or timeout
- Other information

**Main Statistics Log**: `/home/clcc_log/ccllm_log.csv`
- **Column Descriptions**:
  - `time`: Unix timestamp when the log entry was recorded
  - `passively_llm_generate`: Total number of test cases generated by passive LLM workers
  - `active_llm_generate`: Total number of test cases generated by active LLM workers
  - `now_active_llm_worker`: Number of active LLM workers currently running
  - `all_active_llm_worker`: Total number of active LLM worker instances spawned during entire session
  - `saved_count`: Total number of valid test cases successfully saved to disk
  - `process_count`: Total number of test cases processed and evaluated
  - `meets_threshold`: Total number of times a test case's normalized score exceeded the threshold
  - `ban_testcase_count`: Total number of test cases rejected/filtered out

**Coverage Score Log**: `/home/clcc_log/point.csv`
- Detailed coverage scores for each processed test case
- Multiple normalization methods results for analysis

**Discarded Test Cases**: `/home/ban_testcase/`
- Files named `LLM_{reason}_BAN_{number}.txt`
- Contain test cases that were rejected

#### Stop Fuzzing
To stop fuzzing, press `Ctrl+C` in both terminals (terminal-1 and terminal-2).

### Supported DBMS
CLCC currently supports the following DBMS:
- SQLite (3.30.0)
- MySQL (8.0.41)
- MariaDB (10.11.1)
- PostgreSQL (17.6)
- DuckDB (1.2.2)

> Note:To test other versions of a DBMS, edit the corresponding Dockerfile under `[THIS_REPO_PATH]/docker/[DBMS_NAME]/dockers/`

### Run CLCC on DBMS
The overall workflow is the same across DBMSs:
1. prepare seeds under `./docker/set_seed`
2. Build the DBMS-spcific Docker image
3. Start the container (terminal-1) and run `count_feedbackpoint.py`
4. Start fuzzing (terminal-2) by running `clcc_run.py`

#### Command
1. Clone repo
```shell
# If you haven't cloned CLCC yet:
git clone https://github.com/zrclzrcl/CLCC.git
cd ./CLCC
```
2. Select the seed set you want to use
```shell
# Remove the old seed set (clean start)
rm -rf ./docker/set_seed

# Set the seed which you want to use
cp -a ./docker/[DBMS_NAME]/seeds/[SEED_NAME] ./docker/set_seed
```
> **Note**: `[DBMS_NAME]` must be one of `sqlite`, `mysql`, `mariadb`, `duckdb`, `postgre`
> **Note**: `[SEED_NAME]` can be `BSeed`, `BGSeed`, `GSeed`. For DuckDB/MariaDB/MySQL/SQLite, you can also choose `GSeed_deepseek` (the seed which generated by deepseek). For PostgreSQL, you can choose `GSeed_gpt` (the seed which generated by gpt-3.5-turbo). For SQLite, you can choose `GSeed_4omini` (the seed which generated by gpt-4o-mini).
> **Note**: If you want to generate seed by yourself, we prepared a python program to generate. For more detail please see [Seed Generation](#seed-generation).

3. Build docker image
```shell
docker build -f ./docker/[DBMS_NAME]/dockers/clcc_dockerfile -t [DBMS_NAME]_clcc .
```
> **Note**: `[DBMS_NAME]` need to select in `sqlite`, `mysql`, `mariadb`, `duckdb`, `postgre`

4. Start fuzzing
```shell
#You will need two terminal windows for the following steps.
#In terminal-1 run:
docker run -it --name clcc4[DBMS_NAME] [DBMS_NAME]_clcc /bin/bash

cd /home/clcc && python3 count_feedbackpoint.py -t 0.1 -db [DBMS_NAME] -v [DBMS_VERSION] -o 1 -k "Your LLM API KEY Here!" -conf "Config File Path Here" -norm 12 -pn 2 -win 500 -ms "Mapsize for Target DBMS" -mo "The Model You Want to Use" -bu "Your LLM Base URL Here!"

#In terminal-2 run:
docker exec -it clcc4[DBMS_NAME] /bin/bash
#Next command will start fuzz!
python3 clcc_run.py [DBMS_NAME] /home/Squirrel/data/fuzz_root/set_seed/
```
> **Note**: `[DBMS_NAME]` need to select in `sqlite`, `mysql`, `mariadb`, `duckdb`, `postgre`
> **Note**: `[DBMS_VERSION]` need to replace to target version for DBMS, the default version can found in [Supported DBMS](#supported-dbms).
> **Note**: For detail on the `count_feedbackpoint.py` parameters, refer to [CLCC Parameters](#clcc-parameters).

5. Stop & Clean up
To stop fuzzing, press `Ctrl+C` in both terminals (terminal-1 and terminal-2).
For detail on the output file, refer to [What To Expect](#what-to-expect).
To remove the Docker container:
```shell
docker stop clcc4[DBMS_NAME]
docker rm -f clcc4[DBMS_NAME]
```
> **Note**: `[DBMS_NAME]` need to select in `sqlite`, `mysql`, `mariadb`, `duckdb`, `postgre`

### CLCC Parameters
This section explains the parameters of CLCC (`count_feedbackpoint.py`):

#### `-t` Threshold (Required)
- **Type**: float (0.0 – 1.0)
- **Description**: The normalized score threshold that triggers active LLM generation. When a test case's normalized coverage score exceeds this value, an active LLM worker is spawned to generate new test cases based on it.
- **Recommended**: `0.1`
- **Behavior**:
  - The edge coverage effectiveness varies with different `-t` values.
  - **Higher `-t`**: Fewer test cases are sent to the LLM for active generation.
  - **`-t 0`**: All seeds will be sent to the LLM to generate new test cases (maximum LLM usage).
  - **`-t 1`**: Active LLM test case generation is effectively disabled (only passive workers remain active).
- **Example**: `-t 0.1`

#### `-db` Target Database (Required)
- **Type**: string
- **Description**: Specifies the target DBMS to fuzz.
- **Allowed values**: `sqlite`, `mysql`, `postgresql`, `duckdb`, `mariadb`
- **Example**: `-db sqlite`

#### `-o` Test Cases Per Request (Optional)
- **Type**: int
- **Default**: `1`
- **Description**: Number of test cases generated per LLM request.
- **Example**: `-o 3`

#### `-k` API Key (Required)
- **Type**: string
- **Description**: Your LLM API key for authentication.
- **Example**: `-k "sk-xxxxxxxxxxxxxxxx"`

#### `-bu` Base URL (Required)
- **Type**: string
- **Description**: The base URL for the LLM API endpoint.
- **Example**: `-bu "https://api.openai.com/v1/"`

#### `-mo` Model Name (Required)
- **Type**: string
- **Description**: The LLM model to use for test case generation.
- **Example**: `-mo "gemini-2.0-flash"`

#### `-conf` Showmap Config Path (Conditionally Required)
- **Type**: string
- **Description**: Path to the showmap configuration file. This parameter is **required for MySQL, MariaDB, and PostgreSQL**, but **not needed for SQLite and DuckDB** (pass an empty string `""`).
- **Config path for each DBMS**:

| DBMS | Config Path |
|------|-------------|
| SQLite | `""` (empty string) |
| DuckDB | `""` (empty string) |
| MySQL | `/home/Squirrel/data/mysql_showmap_config.yml` |
| MariaDB | `/home/Squirrel/data/mariadb_showmap_config.yml` |
| PostgreSQL | `/home/Squirrel/data/postgre_showmap_config.yml` |

- **Example**: `-conf "/home/Squirrel/data/mysql_showmap_config.yml"`

#### `-ms` Map Size (Required)
- **Type**: int
- **Description**: The AFL_MAP_SIZE value used by the coverage instrumentation. Different DBMSs require different map sizes.
- **Reference values for default DBMS versions**:

| DBMS | Map Size |
|------|----------|
| SQLite | `50000` (280000 for SQLRight) |
| MySQL | `1500000` |
| MariaDB | `360000` |
| PostgreSQL | `308128` |
| DuckDB | `1460000` |

> **Note**: These are reference values for the default DBMS versions listed in [Supported DBMS](#supported-dbms). The actual map size may vary depending on the instrumentation method and DBMS version. Adjust accordingly based on your setup.

- **Example**: `-ms 50000`

#### `-norm` Normalization Method (Required)
- **Type**: int (1–17)
- **Description**: Selects the normalization method for coverage scores. CLCC uses a sliding window (see `-win`) to collect recent coverage scores and computes statistics (mean, median, percentiles). Raw scores are then normalized to a 0–1 range using a tanh-based function.

**How normalization works**:
1. CLCC maintains a sliding window of recent coverage scores.
2. From this window, it computes: min, max, mean, median, and percentiles (10th, 25th, 75th, 90th).
3. A tanh function maps raw scores to 0–1, where:
   - **Midpoint** (center of tanh curve): either the mean or median of the window.
   - **Reference point** (controls curve steepness): a percentile value.
   - **Fitting method**: either slope-based (`k`) or y-value-based (`y`).

**Naming convention**: `[percentile]-[fitting method]-[midpoint]`
- **Percentile**: `lower-4th` (25th), `lower-1st` (10th), `upper-4th` (75th), `upper-1st` (90th)
- **Fitting method**: `k` (slope-based) or `y` (y-value-based)
- **Midpoint**: `avg` (mean) or `median`

| Value | Method | Percentile | Fitting | Midpoint |
|-------|--------|------------|---------|----------|
| 1 | min-max | - | - | - |
| 2 | lower-4th k avg | 25th | slope | mean |
| 3 | lower-4th k median | 25th | slope | median |
| 4 | lower-4th y avg | 25th | y-value | mean |
| 5 | lower-4th y median | 25th | y-value | median |
| 6 | lower-1st k avg | 10th | slope | mean |
| 7 | lower-1st k median | 10th | slope | median |
| 8 | lower-1st y avg | 10th | y-value | mean |
| 9 | lower-1st y median | 10th | y-value | median |
| 10 | upper-4th k avg | 75th | slope | mean |
| 11 | upper-4th k median | 75th | slope | median |
| 12 | upper-4th y avg | 75th | y-value | mean |
| 13 | upper-4th y median | 75th | y-value | median |
| 14 | upper-1st k avg | 90th | slope | mean |
| 15 | upper-1st k median | 90th | slope | median |
| 16 | upper-1st y avg | 90th | y-value | mean |
| 17 | upper-1st y median | 90th | y-value | median |

- **Recommended**: `12` (upper-4th y avg) — uses the 75th percentile with y-value fitting and mean as midpoint, providing a good balance between sensitivity and stability.
- **Example**: `-norm 12`

#### `-pn` Passive LLM Workers (Required)
- **Type**: int
- **Description**: Number of passive LLM worker threads. These workers continuously generate test cases in the background, independent of coverage feedback.
- **Recommended**: `2`

> **Note**: Higher `-pn` values will generate more test cases via passive LLM workers, but will also increase LLM API costs.

- **Example**: `-pn 2`

#### `-maxw` Max LLM Worker (Optional)
- **Type**: int
- **Description**: Upper limit for active LLM worker threads started by coverage feedback (semaphore-controlled). This does not affect passive workers.
- **Default**: `100`
- **Example**: `-maxw 100`

#### `-win` Window Size (Required)
- **Type**: int
- **Description**: Sliding window size for computing normalization statistics. Larger windows provide more stable statistics but slower adaptation.
- **Recommended**: `500`
- **Example**: `-win 500`

### Seed Generation

CLCC provides a script (`src/seed_generate/seed_generate.py`) to generate initial seeds using LLM. This script supports two modes:
- **Few-shot mode**: Uses existing seed files as reference samples to guide LLM generation.
- **Zero-shot mode**: Generates seeds without any reference samples.

#### Prerequisites

- Python 3.11+
- `openai` package: `pip install openai`

#### Usage

```shell
python seed_generate.py \
  -i <input_folder> \
  -o <output_folder> \
  -d <dbms_name> \
  -v <dbms_version> \
  -k <api_key> \
  -u <base_url> \
  -m <model_name> \
  -c <count>
```

#### Parameters

- `-i, --input` (Optional): Path to input folder containing reference sample SQL files. If not provided, zero-shot generation will be used.
- `-o, --output` (Required): Path to output folder where generated seeds will be saved.
- `-d, --dbms` (Required): Target DBMS name (e.g., `PostgreSQL`, `MySQL`, `SQLite`, `DuckDB`, `MariaDB`).
- `-v, --version` (Required): Target DBMS version (e.g., `REL_18_RC1`, `8.0.41`).
- `-k, --api-key` (Required): Your LLM API key.
- `-u, --base-url` (Required): LLM API base URL.
- `-m, --model` (Required): LLM model name (e.g., `gemini-2.0-flash`, `gpt-4o`, `deepseek-chat`).
- `-c, --count` (Optional, default: `10`): Number of seeds to generate.

#### Examples

**Few-shot generation** (using existing seeds as reference):
```shell
python src/seed_generate/seed_generate.py \
  -i "./docker/sqlite/seeds/BSeed" \
  -o "./docker/sqlite/seeds/GSeed_new" \
  -d "SQLite" \
  -v "3.30.0" \
  -k "sk-your-api-key" \
  -u "https://api.openai.com/v1/" \
  -m "gpt-4o" \
  -c 50
```

**Zero-shot generation** (no reference samples):
```shell
python src/seed_generate/seed_generate.py \
  -o "./docker/postgresql/seeds/GSeed_new" \
  -d "PostgreSQL" \
  -v "17.6" \
  -k "sk-your-api-key" \
  -u "https://api.openai.com/v1/" \
  -m "gemini-2.0-flash" \
  -c 30
```

#### Output

Generated seeds are saved as `GSeed_1.txt`, `GSeed_2.txt`, etc. in the specified output folder. Each file contains SQL statements that can be used as initial seeds for CLCC fuzzing.

#### Using Generated Seeds

After generation, copy the seeds to the `set_seed` folder:
```shell
rm -rf ./docker/set_seed
cp -a <output_folder> ./docker/set_seed
```

Then proceed with the normal CLCC fuzzing workflow as described in [Run CLCC on DBMS](#run-clcc-on-dbms).

> **Tip**: Generated seeds can be mixed with existing seeds (e.g., `BSeed`, `BGSeed`) to achieve different testing effects. For example, you can combine LLM-generated seeds with manually crafted seeds to increase diversity and potentially discover more bugs.

## For CLCC (Base on SQLRight)
In the following, we show how to run CLCC with SQLRight as the underlying fuzzer. Below we show how to run CLCC on top of SQLRight. We use SQLite as the example DBMS.
### Command
1. clone repo
```shell
# If you haven't cloned CLCC yet:
git clone https://github.com/zrclzrcl/CLCC.git
cd ./CLCC
```

2. Select the seed set you want to use
```shell
# Remove the old seed set (clean start)
rm -rf ./docker/set_seed

# Set the seed which you want to use
cp -a ./docker/sqlite/seeds/[SEED_NAME] ./docker/set_seed
```
> **Note**: `[SEED_NAME]` can be `BSeed`, `BGSeed`, `GSeed`. For SQLite, you can also choose `GSeed_deepseek` (the seed which generated by deepseek), `GSeed_4omini` (the seed which generated by gpt-4o-mini).
> **Note**: If you want to generate seed by yourself, we prepared a python program to generate. For more detail please see [Seed Generation](#seed-generation).

3. Build docker image
```shell
docker build -f ./docker/sqlite/dockers/clcc_sqlright/clcc_sqlright_dockerfile -t sqlite_clcc .
```

4. Start fuzzing
```shell
#You will need two terminal windows for the following steps.
#In terminal-1 run:
docker run -it --name clcc4sqlite sqlite_clcc /bin/bash
conda activate clcc
cd /home/clcc && python3 count_feedbackpoint.py -t 0.1 -db sqlite -v [DBMS_VERSION] -o 1 -k "Your LLM API KEY Here!" -conf "Config File Path Here" -norm 12 -pn 2 -win 500 -ms "Mapsize for Target DBMS" -mo "The Model You Want to Use" -bu "Your LLM Base URL Here!"

#In terminal-2 run:
docker exec -it clcc4sqlite /bin/bash
#Next command will start fuzz!
./afl-fuzz -i ./inputs -o /tmp/clcc -c 0 -O NOREC -- /home/sqlite/sqlite/sqlite3
```
> **Note**: `[DBMS_VERSION]` need to replace to target version for DBMS, the default version can found in [Supported DBMS](#supported-dbms).
> **Note**: For detail on the `count_feedbackpoint.py` parameters, refer to [CLCC Parameters](#clcc-parameters).

5. Stop & Clean up
To stop fuzzing, press `Ctrl+C` in both terminals (terminal-1 and terminal-2).
For detail on the output file, refer to [What To Expect](#what-to-expect).
To remove the Docker container:
```shell
docker stop clcc4sqlite
docker rm -f clcc4sqlite
```

## Contributing

Contributions are welcome! If you find a bug, have a feature request, or want to improve the documentation, please open an issue or submit a pull request.

### Reporting Issues
When opening an issue, please include:
- Your OS (Ubuntu/Windows) and Docker version
- Target DBMS name and version
- The exact commands you ran (especially `count_feedbackpoint.py` and `clcc_run.py`)
- Relevant logs and files (e.g., `/home/clcc_log/`, `/tmp/fuzz/default/`, and a minimal reproducer if available)

### Pull Requests
- Keep changes focused and well documented.
- For new DBMS support or version updates, please update:
  - `Supported DBMS` section in README
  - Dockerfiles under `./docker/<dbms>/dockers/`
  - Any related configs (e.g., showmap configs)

## License
CLCC is released under the MIT License. See [LICENSE](LICENSE) for details.

Third-party components and their licenses are listed in [THIRD_PARTY_NOTICES.md](THIRD_PARTY_NOTICES.md).

## Acknowledgements
CLCC is developed based on **Squirrel** (MIT License) and relies on fuzzing infrastructure from **AFL++** (Apache License 2.0).

See [THIRD_PARTY_NOTICES.md](THIRD_PARTY_NOTICES.md) for detailed attributions and license information.

## Demo Video
A demo video showing the basic workflow of CLCC is available on Zenodo:

[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.18313784.svg)](https://doi.org/10.5281/zenodo.18313784)
